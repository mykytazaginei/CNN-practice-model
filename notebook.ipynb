{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad5a988c-1095-485a-a88c-002400a872be",
   "metadata": {},
   "source": [
    "Fashion Forward is a new AI-based e-commerce clothing retailer.\n",
    "They want to use image classification to automatically categorize new product listings, making it easier for customers to find what they're looking for. It will also assist in inventory management by quickly sorting items.\n",
    "\n",
    "As a data scientist tasked with implementing a garment classifier, your primary objective is to develop a machine learning model capable of accurately categorizing images of clothing items into distinct garment types such as shirts, trousers, shoes, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ea8065b7-84fc-4376-afef-6db731dec4b3",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 47,
    "lastExecutedAt": 1751383246231,
    "lastExecutedByKernel": "b54fb42c-1d52-499a-8678-b3aa5c6992a9",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "import numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchmetrics import Accuracy, Precision, Recall"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchmetrics import Accuracy, Precision, Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "662e1bf1-943f-4243-9fd4-02ce11609e8d",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 143,
    "lastExecutedAt": 1751383246374,
    "lastExecutedByKernel": "b54fb42c-1d52-499a-8678-b3aa5c6992a9",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "# Load datasets\nfrom torchvision import datasets\nimport torchvision.transforms as transforms\ntrain_transform = transforms.Compose([\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomRotation(45),\n    transforms.ToTensor(),\n    transforms.Resize((128,128)),\n])\ntrain_data = datasets.FashionMNIST(root='./data', train=True, download=True, transform=transforms.ToTensor())\ntest_data = datasets.FashionMNIST(root='./data', train=False, download=True, transform=transforms.ToTensor())\n\nclasses = train_data.classes\nnum_classes = len(train_data.classes)",
    "outputsMetadata": {
     "0": {
      "height": 80,
      "type": "stream"
     },
     "1": {
      "height": 38,
      "type": "stream"
     },
     "2": {
      "height": 122,
      "type": "stream"
     },
     "3": {
      "height": 38,
      "type": "stream"
     },
     "4": {
      "height": 122,
      "type": "stream"
     },
     "5": {
      "height": 38,
      "type": "stream"
     },
     "6": {
      "height": 122,
      "type": "stream"
     },
     "7": {
      "height": 38,
      "type": "stream"
     },
     "8": {
      "height": 59,
      "type": "stream"
     }
    }
   },
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(45),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize((128,128)),\n",
    "])\n",
    "train_data = datasets.FashionMNIST(root='./data', train=True, download=True, transform=transforms.ToTensor())\n",
    "test_data = datasets.FashionMNIST(root='./data', train=False, download=True, transform=transforms.ToTensor())\n",
    "\n",
    "classes = train_data.classes\n",
    "num_classes = len(train_data.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c0a71d-d7d9-4a11-8a9b-55867ea7e0b5",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 56,
    "lastExecutedAt": 1751383246431,
    "lastExecutedByKernel": "b54fb42c-1d52-499a-8678-b3aa5c6992a9",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "# Start coding here\nnum_input_channels = 1\nnum_output_channels = 16\nimage_size = train_data[0][0].shape[1]\n\nclass MultiClassImageClassifier(nn.Module):\n    def __init__(self, num_classes):\n        super(MultiClassImageClassifier, self).__init__()\n        self.conv1 = nn.Conv2d(num_input_channels, num_output_channels, kernel_size = 3, stride = 1, padding = 1)\n        self.elu = nn.ELU()\n        self.maxpool = nn.MaxPool2d(kernel_size = 2, stride = 2)\n        self.flatten = nn.Flatten()\n\n        self.fc = nn.Linear(num_output_channels * (image_size//2)**2, num_classes)\n\n\n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.elu(x)\n        x = self.maxpool(x)\n        x = self.flatten(x)\n        x = self.fc(x)\n\n        return x"
   },
   "outputs": [],
   "source": [
    "num_input_channels = 1\n",
    "num_output_channels = 16\n",
    "image_size = train_data[0][0].shape[1]\n",
    "\n",
    "class MultiClassImageClassifier(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(MultiClassImageClassifier, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(num_input_channels, num_output_channels, kernel_size = 3, stride = 1, padding = 1)\n",
    "        self.elu = nn.ELU()\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "        self.fc = nn.Linear(num_output_channels * (image_size//2)**2, num_classes)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.elu(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e2c7309b-9cbe-4864-b9ab-85262e6cd141",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 78139,
    "lastExecutedAt": 1751383324571,
    "lastExecutedByKernel": "b54fb42c-1d52-499a-8678-b3aa5c6992a9",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "dataloader_train = DataLoader(train_data, batch_size=10, shuffle=True)\n\n\ndef train_model(optimizer, net, num_epoch):\n    num_processed = 0\n    criterion = nn.CrossEntropyLoss()\n    for epoch in range(num_epoch):\n        running_loss = 0\n        num_processed = 0\n        for feauters, labels in dataloader_train:\n            optimizer.zero_grad()\n            outputs = net(feauters)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n            running_loss += loss.item()\n            num_processed += len(labels)\n        print(f'epoch {epoch}, loss: {running_loss / num_processed}')\n    train_loss = running_loss / len(dataloader_train)\n\nnet = MultiClassImageClassifier(num_classes) \noptimizer = optim.Adam(net.parameters(), lr=0.001)\n\ntrain_model(\n    optimizer = optimizer, \n    net = net,\n    num_epoch=1,\n)",
    "outputsMetadata": {
     "0": {
      "height": 38,
      "type": "stream"
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, loss: 0.04269253253931335\n"
     ]
    }
   ],
   "source": [
    "dataloader_train = DataLoader(train_data, batch_size=10, shuffle=True)\n",
    "\n",
    "\n",
    "def train_model(optimizer, net, num_epoch):\n",
    "    num_processed = 0\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    for epoch in range(num_epoch):\n",
    "        running_loss = 0\n",
    "        num_processed = 0\n",
    "        for feauters, labels in dataloader_train:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(feauters)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            num_processed += len(labels)\n",
    "        print(f'epoch {epoch}, loss: {running_loss / num_processed}')\n",
    "    train_loss = running_loss / len(dataloader_train)\n",
    "\n",
    "net = MultiClassImageClassifier(num_classes) \n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "\n",
    "train_model(\n",
    "    optimizer = optimizer, \n",
    "    net = net,\n",
    "    num_epoch=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fa91f5ce-6494-4c44-8eb4-e5db40d3ad29",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 12238,
    "lastExecutedAt": 1751383336811,
    "lastExecutedByKernel": "b54fb42c-1d52-499a-8678-b3aa5c6992a9",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "dataloader_test = DataLoader(test_data, batch_size=10, shuffle=False)\n\naccuracy_metric = Accuracy(task='multiclass', num_classes=num_classes)\nprecision_metric = Precision(task='multiclass', num_classes=num_classes, average=None)\nrecall_metric = Recall(task='multiclass', num_classes=num_classes, average=None)\nnet.eval()\npredictions = []\nfor i, (features, labels) in enumerate(dataloader_test):\n    output = net.forward(features.reshape(-1, 1, image_size, image_size))\n    cat = torch.argmax(output, dim=-1)\n    predictions.extend(cat.tolist())\n    accuracy_metric(cat, labels)\n    precision_metric(cat, labels)\n    recall_metric(cat, labels)\n\n# Compute the metrics\naccuracy = accuracy_metric.compute().item()\nprecision = precision_metric.compute().tolist()\nrecall = recall_metric.compute().tolist()\nprint('Accuracy:', accuracy)\nprint('Precision (per class):', precision)\nprint('Recall (per class):', recall)",
    "outputsMetadata": {
     "0": {
      "height": 164,
      "type": "stream"
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8737000226974487\n",
      "Precision (per class): [0.778268575668335, 0.9887179732322693, 0.8238396644592285, 0.8969072103500366, 0.7512864470481873, 0.966292142868042, 0.7071078419685364, 0.9537329077720642, 0.9686868786811829, 0.909599244594574]\n",
      "Recall (per class): [0.8809999823570251, 0.9639999866485596, 0.781000018119812, 0.8700000047683716, 0.8759999871253967, 0.9459999799728394, 0.5770000219345093, 0.9070000052452087, 0.9589999914169312, 0.9760000109672546]\n"
     ]
    }
   ],
   "source": [
    "dataloader_test = DataLoader(test_data, batch_size=10, shuffle=False)\n",
    "\n",
    "accuracy_metric = Accuracy(task='multiclass', num_classes=num_classes)\n",
    "precision_metric = Precision(task='multiclass', num_classes=num_classes, average=None)\n",
    "recall_metric = Recall(task='multiclass', num_classes=num_classes, average=None)\n",
    "net.eval()\n",
    "predictions = []\n",
    "for i, (features, labels) in enumerate(dataloader_test):\n",
    "    output = net.forward(features.reshape(-1, 1, image_size, image_size))\n",
    "    cat = torch.argmax(output, dim=-1)\n",
    "    predictions.extend(cat.tolist())\n",
    "    accuracy_metric(cat, labels)\n",
    "    precision_metric(cat, labels)\n",
    "    recall_metric(cat, labels)\n",
    "\n",
    "# Compute the metrics\n",
    "accuracy = accuracy_metric.compute().item()\n",
    "precision = precision_metric.compute().tolist()\n",
    "recall = recall_metric.compute().tolist()\n",
    "print('Accuracy:', accuracy)\n",
    "print('Precision (per class):', precision)\n",
    "print('Recall (per class):', recall)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Welcome to DataCamp Workspaces.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
